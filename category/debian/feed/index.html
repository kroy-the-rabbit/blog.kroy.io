<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>Debian &#8211; blog.kroy.io</title>
	<atom:link href="https://blog.kroy.io/category/debian/feed/" rel="self" type="application/rss+xml" />
	<link>https://blog.kroy.io/</link>
	<description>computers, tech, and whatever other random stuff crosses my mind.</description>
	<lastBuildDate>Mon, 07 Dec 2020 15:37:33 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.6</generator>

<image>
	<url>https://blog.kroy.io/wp-content/uploads/2020/04/cropped-android-chrome-512x512-3-32x32.png</url>
	<title>Debian &#8211; blog.kroy.io</title>
	<link>https://blog.kroy.io/</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">166765678</site>	<item>
		<title>Migrating an EFI Linux Install to a new Server</title>
		<link>https://blog.kroy.io/2019/10/28/migrating-a-efi-linux-install-to-a-new-server/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=migrating-a-efi-linux-install-to-a-new-server</link>
		
		<dc:creator><![CDATA[Kroy]]></dc:creator>
		<pubDate>Mon, 28 Oct 2019 19:50:51 +0000</pubDate>
				<category><![CDATA[Debian]]></category>
		<category><![CDATA[Storage]]></category>
		<guid isPermaLink="false">https://blog.kroy.io/?p=394</guid>

					<description><![CDATA[Recently, during my Great Rack Migration madness, I migrated the system drive for my main NAS to a new Supermicro 846. One of the hurdles I ran into was that&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Recently, during my Great Rack Migration madness, I migrated the system drive for my <a href="https://blog.kroy.io/2019/10/28/the-great-rack-migration-dell-r420/">main NAS to a new Supermicro 846</a>. </p>



<hr class="wp-block-separator"/>



<p>One of the hurdles I ran into was that my system refused to boot after I moved the drive.  The install was EFI based, and the new system didn&#8217;t have the appropriate NVRAM variables to determine which OS to boot.</p>



<p>Fortunately, EFI provides the EFI shell, and that shell makes this problem extremely simple to fix.</p>



<p>First off, to replicate the setup, I create a new small Debian VM on ESXi and installed Buster.  An important step to take if you want to experiment in the EFI shell, is to make sure the VM actually boots via EFI, which the Debian template doesn&#8217;t do automatically:</p>



<figure class="wp-block-image"><img loading="lazy" width="845" height="990" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-19.png" alt="" class="wp-image-431" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-19.png 845w, https://blog.kroy.io/wp-content/uploads/2019/10/image-19-256x300.png 256w, https://blog.kroy.io/wp-content/uploads/2019/10/image-19-768x900.png 768w, https://blog.kroy.io/wp-content/uploads/2019/10/image-19-300x351.png 300w" sizes="(max-width: 845px) 100vw, 845px" /></figure>



<p>For this experiment, it is important to make this change before installing the VM.</p>



<hr class="wp-block-separator"/>



<p>Within a VM in ESXi for EFI, it&#8217;s fairly trivial to replicate what would happen if you moved a boot drive from one system to another.  The NVRAM file just needs to be deleted (preferably while the VM is powered down).</p>



<p>This involves manually browsing the datastore and deleting the <code>vmname.nvram</code> file that&#8217;s in the VM Folder on the datastore.</p>



<figure class="wp-block-image"><img loading="lazy" width="995" height="567" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-21.png" alt="" class="wp-image-433" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-21.png 995w, https://blog.kroy.io/wp-content/uploads/2019/10/image-21-300x171.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-21-768x438.png 768w, https://blog.kroy.io/wp-content/uploads/2019/10/image-21-850x484.png 850w" sizes="(max-width: 995px) 100vw, 995px" /></figure>



<p>Once the nvram file is deleted, the VM will refuse to boot:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="565" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-22-1024x565.png" alt="" class="wp-image-434" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-22-1024x565.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/10/image-22-300x165.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-22-768x423.png 768w, https://blog.kroy.io/wp-content/uploads/2019/10/image-22-850x469.png 850w, https://blog.kroy.io/wp-content/uploads/2019/10/image-22.png 1333w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>But reseting and tapping ESC quickly gets the the boot manager menu, which allows entering an EFI shell.  Some servers boot straight into the EFI shell if they can&#8217;t find what to boot:</p>



<figure class="wp-block-image"><img loading="lazy" width="1022" height="806" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-24.png" alt="" class="wp-image-436" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-24.png 1022w, https://blog.kroy.io/wp-content/uploads/2019/10/image-24-300x237.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-24-768x606.png 768w, https://blog.kroy.io/wp-content/uploads/2019/10/image-24-850x670.png 850w" sizes="(max-width: 1022px) 100vw, 1022px" /></figure>



<p>Which leads to:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="715" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-25-1024x715.png" alt="" class="wp-image-437" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-25-1024x715.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/10/image-25-300x209.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-25-768x536.png 768w, https://blog.kroy.io/wp-content/uploads/2019/10/image-25-850x593.png 850w, https://blog.kroy.io/wp-content/uploads/2019/10/image-25.png 1047w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<hr class="wp-block-separator"/>



<p>In the EFI shell, available drives are enumerated as <code>fs0:</code>, <code>fs1:</code>, etc.</p>



<p>Switch to a drive and see if it&#8217;s a drive that has EFI stuff on it (dir or ls works):</p>



<pre class="wp-block-code"><code>fs0:
dir</code></pre>



<p>If the <code>EFI</code> folder exists, that&#8217;s the right spot. </p>



<figure class="wp-block-image"><img loading="lazy" width="662" height="269" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-26.png" alt="" class="wp-image-438" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-26.png 662w, https://blog.kroy.io/wp-content/uploads/2019/10/image-26-300x122.png 300w" sizes="(max-width: 662px) 100vw, 662px" /></figure>



<pre class="wp-block-code"><code>cd EFI
dir
cd debian
dir</code></pre>



<figure class="wp-block-image"><img loading="lazy" width="801" height="509" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-27.png" alt="" class="wp-image-439" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-27.png 801w, https://blog.kroy.io/wp-content/uploads/2019/10/image-27-300x191.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-27-768x488.png 768w" sizes="(max-width: 801px) 100vw, 801px" /></figure>



<p>The relevant file should be named <code>grubx64.efi</code>.  Typing that (or using tab completion to select it), will boot your system:</p>



<figure class="wp-block-image"><img loading="lazy" width="809" height="462" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-29.png" alt="" class="wp-image-441" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-29.png 809w, https://blog.kroy.io/wp-content/uploads/2019/10/image-29-300x171.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-29-768x439.png 768w" sizes="(max-width: 809px) 100vw, 809px" /></figure>



<p>Once your system is booted, you just need to rerun and update grub to restore your system&#8217;s ability to boot without the EFI shell.</p>



<p>It&#8217;s important that your EFI partition is properly mounted, which should happen, but you might need to mount it manually:</p>



<figure class="wp-block-image"><img loading="lazy" width="906" height="276" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-30.png" alt="" class="wp-image-442" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-30.png 906w, https://blog.kroy.io/wp-content/uploads/2019/10/image-30-300x91.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-30-768x234.png 768w, https://blog.kroy.io/wp-content/uploads/2019/10/image-30-850x259.png 850w" sizes="(max-width: 906px) 100vw, 906px" /></figure>



<p>Once you confirm your EFI partition is mounted, reinstall grub:</p>



<pre class="wp-block-code"><code>sudo grub-install /dev/sda
sudo update-grub</code></pre>



<figure class="wp-block-image"><img loading="lazy" width="914" height="288" src="https://blog.kroy.io/wp-content/uploads/2019/10/image-20.png" alt="" class="wp-image-432" srcset="https://blog.kroy.io/wp-content/uploads/2019/10/image-20.png 914w, https://blog.kroy.io/wp-content/uploads/2019/10/image-20-300x95.png 300w, https://blog.kroy.io/wp-content/uploads/2019/10/image-20-768x242.png 768w, https://blog.kroy.io/wp-content/uploads/2019/10/image-20-850x268.png 850w" sizes="(max-width: 914px) 100vw, 914px" /></figure>



<p>That&#8217;s it!  The system should be booting again.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">394</post-id>	</item>
		<item>
		<title>10 gigabit inter-VLAN with a Mikrotik RB4011</title>
		<link>https://blog.kroy.io/2019/09/13/10-gigabit-inter-vlan-with-a-mikrotik-rb4011/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=10-gigabit-inter-vlan-with-a-mikrotik-rb4011</link>
		
		<dc:creator><![CDATA[Kroy]]></dc:creator>
		<pubDate>Fri, 13 Sep 2019 14:35:30 +0000</pubDate>
				<category><![CDATA[Debian]]></category>
		<category><![CDATA[mikrotik]]></category>
		<category><![CDATA[Networking]]></category>
		<category><![CDATA[RouterOS]]></category>
		<category><![CDATA[Routing]]></category>
		<guid isPermaLink="false">https://blog.kroy.io/?p=300</guid>

					<description><![CDATA[Something I see pop up fairly regularly on a few of the forums, Discords, and subreddits that I hang out on is that the RB4011 is not capable of 10&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Something I see pop up fairly regularly on a few of the forums, Discords, and subreddits that I hang out on is that the <a href="https://amzn.to/387CKrn" target="_blank" rel="noreferrer noopener" aria-label="RB4011 (opens in a new tab)">RB4011</a> is not capable of 10 gigabit routing</p>



<p>Guess what?</p>



<h4>THAT&#8217;S WRONG</h4>



<p>I&#8217;d be lying if I said that this xkcd wasn&#8217;t me sometimes:</p>



<div class="wp-block-image"><figure class="aligncenter"><img src="https://imgs.xkcd.com/comics/duty_calls.png" alt=""/><figcaption><a href="https://xkcd.com/386/">https://xkcd.com/386/</a></figcaption></figure></div>



<p>Of course, whenever this pops up I&#8217;m not in a position to demonstrate the proof.  It definitely can go almost full 10Gb.</p>



<p><em>But</em> you say<em>, it&#8217;s only got a single SFP+ port!</em></p>



<p>That&#8217;s what full-duplex is for!</p>



<p>I&#8217;ve got a number of these devices and have tested them extensively.  The RB4011 is definitely capable of 10 gigabit routing, in a router-on-a-stick fashion. </p>



<h3>The Proof</h3>



<p>As this is something that comes up almost weekly, I have decided it&#8217;s time to officially document an RB4011 going almost full 10 gigabit.</p>



<p>For this setup, I reset the config on a RB4011 to empty, spun up a simple Debian VM, and connected an existing host and the VM through the RB4011.  </p>



<p>As you can see, the hacky result on my desktop:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="768" src="https://blog.kroy.io/wp-content/uploads/2019/09/IMG_0332-1024x768.jpg" alt="" class="wp-image-302" srcset="https://blog.kroy.io/wp-content/uploads/2019/09/IMG_0332-1024x768.jpg 1024w, https://blog.kroy.io/wp-content/uploads/2019/09/IMG_0332-300x225.jpg 300w, https://blog.kroy.io/wp-content/uploads/2019/09/IMG_0332-768x576.jpg 768w, https://blog.kroy.io/wp-content/uploads/2019/09/IMG_0332-850x638.jpg 850w, https://blog.kroy.io/wp-content/uploads/2019/09/IMG_0332.jpg 1685w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<h4>The Configs:</h4>



<p>This config is about as simple as it gets.  Two VLANs on the <code>sfp-sfpplus1</code> interface, and IP addresses on the respective interfaces. </p>



<pre class="wp-block-code"><code># jan/02/1970 00:27:33 by RouterOS 6.45.5
# software id = K5KS-T8WB
#
# model = RB4011iGS+
# serial number = xxxxxxxxxx
/interface vlan
add interface=sfp-sfpplus1 name=VLAN22 vlan-id=22
add interface=sfp-sfpplus1 name=VLAN2222 vlan-id=2222
/interface wireless security-profiles
set [ find default=yes ] supplicant-identity=MikroTik
/ip address
add address=10.22.22.10/24 interface=VLAN22 network=10.22.22.0
add address=10.222.222.1/24 interface=VLAN2222 network=10.222.222.0</code></pre>



<p><code>VLAN2222</code> is a new VLAN I spun up for this test, and <code>VLAN22</code> is an existing VLAN on my network, where a host is running <code>iperf3 -s</code></p>



<p>The Debian VM is also very straightforward.  ESXi, with a few vCPUs (sometimes at higher iperf3 tests, the CPU can get tapped out), and network connected to <code>VLAN2222</code></p>



<figure class="wp-block-image"><img loading="lazy" width="732" height="575" src="https://blog.kroy.io/wp-content/uploads/2019/09/image.png" alt="" class="wp-image-303" srcset="https://blog.kroy.io/wp-content/uploads/2019/09/image.png 732w, https://blog.kroy.io/wp-content/uploads/2019/09/image-300x236.png 300w" sizes="(max-width: 732px) 100vw, 732px" /></figure>



<p>A static IP and default route, and we are ready to roll:</p>



<figure class="wp-block-image"><img loading="lazy" width="751" height="253" src="https://blog.kroy.io/wp-content/uploads/2019/09/image-1.png" alt="" class="wp-image-304" srcset="https://blog.kroy.io/wp-content/uploads/2019/09/image-1.png 751w, https://blog.kroy.io/wp-content/uploads/2019/09/image-1-300x101.png 300w" sizes="(max-width: 751px) 100vw, 751px" /></figure>



<hr class="wp-block-separator"/>



<h2>The Results</h2>



<p>The results sort of speak for themselves.  With an iperf3 to a host on VLAN22 (two streams), we have no issues going 10Gb:</p>



<figure class="wp-block-image"><img loading="lazy" width="708" height="826" src="https://blog.kroy.io/wp-content/uploads/2019/09/image-2.png" alt="" class="wp-image-305" srcset="https://blog.kroy.io/wp-content/uploads/2019/09/image-2.png 708w, https://blog.kroy.io/wp-content/uploads/2019/09/image-2-257x300.png 257w, https://blog.kroy.io/wp-content/uploads/2019/09/image-2-300x350.png 300w" sizes="(max-width: 708px) 100vw, 708px" /><figcaption>10Gb yo</figcaption></figure>



<p>With a single stream, it fairs moderately worse:</p>



<figure class="wp-block-image"><img loading="lazy" width="703" height="305" src="https://blog.kroy.io/wp-content/uploads/2019/09/image-3.png" alt="" class="wp-image-306" srcset="https://blog.kroy.io/wp-content/uploads/2019/09/image-3.png 703w, https://blog.kroy.io/wp-content/uploads/2019/09/image-3-300x130.png 300w" sizes="(max-width: 703px) 100vw, 703px" /></figure>



<p>Note that is on a basic 1500 MTU network, so I did not set jumbo frames. </p>



<p>And what&#8217;s the CPU doing during this?</p>



<figure class="wp-block-image"><img loading="lazy" width="339" height="68" src="https://blog.kroy.io/wp-content/uploads/2019/09/image-4.png" alt="" class="wp-image-307" srcset="https://blog.kroy.io/wp-content/uploads/2019/09/image-4.png 339w, https://blog.kroy.io/wp-content/uploads/2019/09/image-4-300x60.png 300w" sizes="(max-width: 339px) 100vw, 339px" /></figure>



<h2>Firewalls and IPv6</h2>



<p>While I&#8217;m not going to do it here, I have done testing in the past with IPv6 and firewalling:</p>



<ul><li>With a fairly extensive firewall, the RB4011 will still do 10Gb, a<em>s long as fast track is enabled!!</em> The CPU in this scenario runs at about 80%</li><li>IPv6 performance is abysmal, which is part of the reason I&#8217;ve started moving away from these.</li><li>Without fasttrack, the CPU will be at 100% at about 1.6Gbps.  IPv6 can&#8217;t use fasttrack, therefore IPv6 inter-VLAN stalls out at less than 2Gbps.</li></ul>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">300</post-id>	</item>
		<item>
		<title>Battle of the Virtual Routers</title>
		<link>https://blog.kroy.io/2019/08/23/battle-of-the-virtual-routers/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=battle-of-the-virtual-routers</link>
		
		<dc:creator><![CDATA[Kroy]]></dc:creator>
		<pubDate>Fri, 23 Aug 2019 19:23:31 +0000</pubDate>
				<category><![CDATA[Debian]]></category>
		<category><![CDATA[Networking]]></category>
		<category><![CDATA[pfsense]]></category>
		<category><![CDATA[RouterOS]]></category>
		<category><![CDATA[Routing]]></category>
		<category><![CDATA[VyOS]]></category>
		<guid isPermaLink="false">https://blog2.kroy.io/2019/08/23/battle-of-the-virtual-routers/</guid>

					<description><![CDATA[This is going to be a bit of a long post, so I&#8217;ll be brief in the intro. &#160; Over the last few years, I&#8217;ve become enamored with routing. &#160;As&#8230;]]></description>
										<content:encoded><![CDATA[
<p>This is going to be a bit of a long post, so I&#8217;ll be brief in the intro. &nbsp;</p>





<p>Over the last few years, I&#8217;ve become enamored with routing. &nbsp;As part of that, I&#8217;ve spent a lot of time exploring the various virtual routing platforms, trying to eek out the best performance possible. &nbsp;So I decided to put them all head-to-head in a virtual setting and see how they fare. &nbsp;</p>



<p>The victims:</p>



<ul><li>pfSense 2.4.4-p3</li><li>OPNSense 19.7</li><li>VyOS 1.2.2</li><li>Mikrotik Cloud Hosted Router 6.45.3, unlimited license (CHR)</li><li>Just basic Debian Buster running FRR</li><li>All tests were done with <code>iperf3 -c IP -P2</code>. &nbsp;I tried a number of different combinations of window sizes, number of streams, etc, and everything was pretty close to equal. &nbsp;UDP obviously gave much bigger numbers, but I&#8217;m interested in TCP for right now. &nbsp;</li></ul>



<p>For the purpose of testing and to make all things equal, pfSense and OPNSense will be running with NAT disabled and <code>pfctl -d</code>, to remove the potential slow-downs from packet inspection. &nbsp;The CHR, Debian, VyOS installs won&#8217;t have firewalls running.</p>



<p>If you are just interested in the final results, they are <a href="/battle-of-the-virtual-routers/#finalresults_kvm">HERE</a>. &nbsp;Or maybe you&#8217;d like the results when I ran the test on ESXi <a href="/battle-of-the-virtual-routers/#finalresults_esxi">HERE</a>.</p>



<hr class="wp-block-separator"/>



<h2 id="the-layout">The Layout</h2>



<p>They say a picture tells a thousand words, so I think a simple network diagram should illustrate the setup:</p>



<figure class="wp-block-image"><img loading="lazy" width="812" height="788" src="https://blog.kroy.io/wp-content/uploads/2019/08/network-diagram.png" alt="" class="wp-image-37" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/network-diagram.png 812w, https://blog.kroy.io/wp-content/uploads/2019/08/network-diagram-300x291.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/network-diagram-768x745.png 768w" sizes="(max-width: 812px) 100vw, 812px" /></figure>



<p>I&#8217;ll be replacing the firewall image in this picture with the various victims.</p>



<p>I&#8217;ve got a <em>LOT</em> of routing going on in my network. &nbsp;At last count, I think I have at least 8 hops from one end of my network to the other, so OSPF simplifies adding new subnets behind various routers. &nbsp;In most cases, I don&#8217;t even bother to add default routes to new hosts as OSPF floods the default route from my edge device. &nbsp;</p>



<hr class="wp-block-separator"/>



<h2 id="the-hardware">The Hardware</h2>



<p>For these tests, I wanted to use KVM. &nbsp;The network stack on ESXi has been driving me crazy lately, so I was hoping KVM would give me some decent results. &nbsp;Proxmox makes this pretty trivial, so that&#8217;s what I set up.</p>



<ul><li>Proxmox 6</li><li>rootonzfs on an SSD</li><li>64GB of RAM</li><li>D-1521, with Dual X550/552 10G-BaseT ports</li></ul>



<p>This is a more-than-capable machine for these tests, though I will say I&#8217;ve gotten better results on my Broadwell E5.</p>



<p>The networking config on the host is pretty simple. To further isolate things, I have two different ports running as Trunks. &nbsp;Proxmox networking goes over one, and the networking for this test lab goes out of the other.</p>



<p>I did try using OVS, just to see if the results were any different, but they weren&#8217;t. &nbsp;So on Proxmox, the network config is pretty simple:</p>



<pre class="wp-block-code"><code>auto lo
    iface lo inet loopback

    iface eno4 inet manual

    auto ens2
    iface eno2 inet manual

    auto eno3
    iface eno3 inet manual

    auto vmbr0.3
    iface vmbr0.3 inet static
       address 10.3.1.84/24
       gateway 10.3.1.1


    auto vmbr0
    iface vmbr0 inet manual
        bridge_ports eno3
        bridge_stp off
        bridge_fd 0
        bridge_vlan_aware yes

    auto vmbr1
    iface vmbr1 inet manual
        bridge_ports ens2
        bridge_stp off
        bridge_fd 0
        bridge_vlan_aware yes</code></pre>



<p>All &nbsp;VMs are connected to <code>vmbr1</code>.</p>



<p>The VMs should be fairly equal. &nbsp;CPU-wise, I&#8217;ve gone with 2c2t. &nbsp;RAM is 2GB, which is overkill for basically any of these</p>



<hr class="wp-block-separator"/>



<h2 id="the-linux-crowd">The Linux crowd</h2>



<p>The first batch of routers are all based on Linux. &nbsp;The VyOS version I used (1.2.2), is based on Debian Jessie with a modern 4.19 kernel and runs FRR. &nbsp;The CHR is based on an ancient 3.x Linux kernel. &nbsp;The plain Linux install will be the latest Debian Buster, with the repo version of FRR, 6.0.1.</p>



<hr class="wp-block-separator"/>



<h3 id="vyos">VyOS</h3>



<p>As a contributor, I have access to the current VyOS <code>crux</code> version, 1.2.2. &nbsp;For routing, it uses FRR 7.0.1.</p>



<h4 id="config">config</h4>



<p>The config is painfully simple. &nbsp;Three interfaces, WAN/LAN/LAN2, OSPF, DHCP on the LAN interfaces (for ease of use) and enabling SSH.</p>



<p>As initially mentioned, there&#8217;s been no firewall configured here. &nbsp;I&#8217;m only interested in pure routing performance.</p>



<pre class="wp-block-code"><code>interfaces {
         ethernet eth0 {
             duplex auto
             smp-affinity auto
             speed auto
             vif 500 {
                 address 10.253.253.2/30
             }
             vif 2222 {
                 address 10.222.222.1/24
             }
             vif 2223 {
                 address 10.223.223.1/24
             }
         }
         loopback lo {
         }
     }
     protocols {
         ospf {
             area 0.0.0.0 {
                 network 10.253.253.0/30
             }
             redistribute {
                 connected {
                     metric-type 2
                 }
             }
         }
     }
     service {
         dhcp-server {
             shared-network-name VLAN2222 {
                 subnet 10.222.222.0/24 {
                     default-router 10.222.222.1
                     dns-server 10.53.53.53
                     range 0 {
                         start 10.222.222.10
                         stop 10.222.222.200
                     }
              }
              shared-network-name VLAN2223 {
                 subnet 10.223.223.0/24 {
                     default-router 10.223.223.1
                     dns-server 10.53.53.53
                     range 0 {
                         start 10.223.223.10
                         stop 10.223.223.200
                     }
                 }
             }
         }
         ssh {
             port 22
         }
     }</code></pre>



<h4 id="boottime">boot time</h4>



<p>VyOS generally boots pretty quickly, at least with a simple config. &nbsp;37 seconds from starting the VM to routing packets. &nbsp;That&#8217;s also with the bootloader timeout. &nbsp;</p>



<h4 id="iperf3results">iperf3 results</h4>



<p>Here are the results of a simple iperf3 test. &nbsp;From <code>10.223.223.11</code> to <code>10.222.222.12</code> &nbsp;:</p>



<pre class="wp-block-code"><code>     [ ID] Interval           Transfer     Bitrate
     [  5]   0.00-10.04  sec  7.17 GBytes  6.14 Gbits/sec                  receiver
     [  8]   0.00-10.04  sec  7.22 GBytes  6.18 Gbits/sec                  receiver
     [SUM]   0.00-10.04  sec  14.4 GBytes  12.3 Gbits/sec                  receiver</code></pre>



<p>I would be lying if I said I wasn&#8217;t at least a little bit disappointed with those results. &nbsp;Especially since the direct VM-&gt;VM on the same layer2 test shows quite a bit more performance:</p>



<pre class="wp-block-code"><code>    [ ID] Interval           Transfer     Bitrate
    [  5]   0.00-10.04  sec  11.8 GBytes  10.1 Gbits/sec                  receiver
    [  8]   0.00-10.04  sec  11.7 GBytes  10.0 Gbits/sec                  receiver
    [SUM]   0.00-10.04  sec  23.5 GBytes  20.1 Gbits/sec                  receiver</code></pre>



<p>I guess it&#8217;s just the hardware. &nbsp;</p>



<p>I have a few VyOS VMs on ESXi as my main intervlan routing devices on bigger hardware, and those are capable of 15-30Gbps routing between VMs on the same host depending on how busy the host is.</p>



<h4 id="speedtest">speedtest</h4>



<p>I have gigabit Internet, so I wanted to make sure results are at least close to what I would get natively. &nbsp;</p>



<p>Given that this lab is behind a few routers, and my network is fairly busy at any point in time, these results are close enough to gigabit to count. &nbsp;</p>



<figure class="wp-block-image"><img loading="lazy" width="830" height="170" src="https://blog.kroy.io/wp-content/uploads/2019/08/vyos-speedtest.png" alt="" class="wp-image-38" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/vyos-speedtest.png 830w, https://blog.kroy.io/wp-content/uploads/2019/08/vyos-speedtest-300x61.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/vyos-speedtest-768x157.png 768w" sizes="(max-width: 830px) 100vw, 830px" /></figure>



<h4 id="cpuusage">CPU usage</h4>



<p>I was curious what kind of CPU usage there would be under max routing load. &nbsp;Obviously adding a firewall would add to this a bit:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="596" src="https://blog.kroy.io/wp-content/uploads/2019/08/vyos-cpuusage-speedtest-1024x596.png" alt="" class="wp-image-39" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/vyos-cpuusage-speedtest-1024x596.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/vyos-cpuusage-speedtest-300x175.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/vyos-cpuusage-speedtest-768x447.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/vyos-cpuusage-speedtest-850x495.png 850w, https://blog.kroy.io/wp-content/uploads/2019/08/vyos-cpuusage-speedtest.png 1142w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<hr class="wp-block-separator"/>



<h3 id="debian-frr">Debian/FRR</h3>



<p>The was just a plain Debian Buster install with FRR installed. &nbsp;Honestly, most of the results are throwaway, since they are largely identical to VyOS.</p>



<h4 id="config">config</h4>



<p>There isn&#8217;t much in the way of special config here. &nbsp;Enabling <code>net.ipv4.ip_forward = 1</code> in <code>/etc/sysctl.conf</code> is a must.</p>



<p>Networking ( <code>/etc/network/interfaces</code> ):<br></p>



<pre class="wp-block-code"><code># The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
auto ens18
iface ens18


auto vlan500
iface vlan500
  bridge-ports ens18.500
  bridge-stp on
  address 10.253.253.2/30
  gateway 10.253.253.1
  dns-nameservers 10.53.53.53


auto vlan2222
iface vlan2222
  bridge-ports ens18.2222
  bridge-stp on
    address 10.222.222.1/24

auto vlan2223
iface vlan2223
  bridge-ports ens18.2223
  bridge-stp on
    address 10.223.223.1/24</code></pre>



<p>FRR ( <code>/etc/frr/frr.conf</code> ):</p>



<pre class="wp-block-code"><code>frr version 6.0.2
frr defaults traditional
hostname ovs
log syslog informational
service integrated-vtysh-config
!
router ospf
 redistribute connected
 network 10.253.253.0/30 area 0
!
line vty</code></pre>



<p>isc-dhcpd ( <code>/etc/dhcpd.conf</code> ):</p>



<pre class="wp-block-code"><code>option domain-name-servers 10.53.53.53;

default-lease-time 600;
max-lease-time 7200;

subnet 10.222.222.0 netmask 255.255.255.0 {
    range 10.222.222.10 10.222.222.200;
    option routers 10.222.222.1;
}

subnet 10.223.223.0 netmask 255.255.255.0 {
    range 10.223.223.10 10.223.223.200;
    option routers 10.223.223.1;
}</code></pre>



<h4 id="boottime">boot time</h4>



<p>This is the one metric that isn&#8217;t throwaway compared to VyOS. &nbsp;19 seconds from power-on to routing is FAST, and that&#8217;s with 5 seconds of grub time. &nbsp;This means if you are interested in super fast boot times, it&#8217;s probably worth your time learning how to set up a router/firewall on unadulterated Linux.</p>



<h4 id="iperf3results">iperf3 results</h4>



<p>As hinted at, the results are very similar to the VyOS results. &nbsp;Not surprising considering same kernel versions, both are FRR, etc.</p>



<pre class="wp-block-code"><code> [ ID] Interval           Transfer     Bitrate
 [  5]   0.00-10.04  sec  7.14 GBytes  6.11 Gbits/sec                  receiver
 [  8]   0.00-10.04  sec  7.08 GBytes  6.06 Gbits/sec                  receiver
 [SUM]   0.00-10.04  sec  14.2 GBytes  12.2 Gbits/sec                  receiver</code></pre>



<h4 id="speedtest">speedtest</h4>



<p>With these speedtest results, I must have found a rare moment when the rest of my network was mostly idle:</p>



<figure class="wp-block-image"><img loading="lazy" width="456" height="113" src="https://blog.kroy.io/wp-content/uploads/2019/08/frr-speedtest.png" alt="" class="wp-image-40" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/frr-speedtest.png 456w, https://blog.kroy.io/wp-content/uploads/2019/08/frr-speedtest-300x74.png 300w" sizes="(max-width: 456px) 100vw, 456px" /></figure>



<h4 id="cpuusageduringheavyrouting">CPU usage during heavy routing</h4>



<p>Again, similar and expected results:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="625" src="https://blog.kroy.io/wp-content/uploads/2019/08/frr-cpuusage-speedtest-1024x625.png" alt="" class="wp-image-41" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/frr-cpuusage-speedtest-1024x625.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/frr-cpuusage-speedtest-300x183.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/frr-cpuusage-speedtest-768x469.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/frr-cpuusage-speedtest-850x519.png 850w, https://blog.kroy.io/wp-content/uploads/2019/08/frr-cpuusage-speedtest.png 1128w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>All in all, the differences between FRR and VyOS were pretty minimal. &nbsp;Despite the longer boot times, I would probably just &nbsp;use VyOS, for the CLI and ease of configuration.</p>



<hr class="wp-block-separator"/>



<h3 id="chr">CHR</h3>



<p>I&#8217;m a heavy Mikrotik user otherwise (multiple RB4011s, CRS317, 326, hex, haps, etc), and CHRs are something I feel like should really perform well.</p>



<p>This is where things started to get a bit funky. &nbsp;I&#8217;ll be honest here, the CHR results were the ones I was most interested in. &nbsp;I have <em>NEVER </em>been able to get decent routing results out of a CHR, I was hoping the proverbial &#8220;blank slate&#8221; would allow me to get the real picture.</p>



<p>The VM was a freshly installed (via systemrescuecd), 6.45.3 CHR, unlocked with a purchased unlimited license. &nbsp;</p>



<h4 id="config">config</h4>



<p>The config here was painfully simple again. &nbsp;A few interfaces and DHCP servers.</p>



<pre class="wp-block-code"><code>/interface ethernet 
set [ find default-name=ether1 ] disable-running-check=no name=Trunk
/interface vlan
add interface=Trunk name=LAN vlan-id=2222
add interface=Trunk name=LAN2 vlan-id=2223
add interface=Trunk name=WAN vlan-id=500
/interface wireless security-profiles
set [ find default=yes ] supplicant-identity=MikroTik
/ip pool
add name=dhcp_pool0 ranges=10.222.222.2-10.222.222.254
add name=dhcp_pool1 ranges=10.223.223.2-10.223.223.254
/ip dhcp-server
add address-pool=dhcp_pool0 disabled=no interface=LAN name=dhcp1
add address-pool=dhcp_pool1 disabled=no interface=LAN2 name=dhcp2
/routing ospf instance
set [ find default=yes ] redistribute-connected=as-type-2 router-id=10.253.253.2
/ip address
add address=10.253.253.2/30 interface=WAN network=10.253.253.0
add address=10.222.222.1/24 interface=LAN network=10.222.222.0
add address=10.223.223.1/24 interface=LAN2 network=10.223.223.0
/ip dhcp-server network
add address=10.222.222.0/24 gateway=10.222.222.1
add address=10.223.223.0/24 gateway=10.223.223.1
/ip dns
set servers=10.53.53.53
/routing ospf network
add area=backbone network=10.253.253.0/30
/system clock
set time-zone-name=America/Chicago</code></pre>



<h4 id="boottime">boot time</h4>



<p>Frankly, the boot time was really about the only decent thing about my CHR tests. &nbsp;12 seconds, which is in-line with the other Linux results, there&#8217;s just no 5 second timeout in grub to contend with here.</p>



<h4 id="iperf3results">iperf3 results</h4>



<p>These results really made me question my testing methodology. &nbsp;Abysmal is about all I can say about it:</p>



<pre class="wp-block-code"><code>[ ID] Interval           Transfer     Bitrate
[  5]   0.00-10.04  sec  1.84 GBytes  1.58 Gbits/sec                  receiver
[  8]   0.00-10.04  sec  1.67 GBytes  1.43 Gbits/sec                  receiver
[SUM]   0.00-10.04  sec  3.51 GBytes  3.01 Gbits/sec                  receiver</code></pre>



<p>I really spent a lot of time fighting these results. &nbsp;They felt way off. &nbsp;Some of the troubleshooting:</p>



<ul><li>Messing with offload settings, both in the host and in the VM. &nbsp;</li><li>Using different NIC types. &nbsp;Maybe the CHR didn&#8217;t like virtio.</li><li>Using a Mellanox vs an Intel NIC. &nbsp;The results were the same whether between the same bridge on Proxmox, to another physical host over the 10Gb Trunk link, etc.</li><li>Changing around all the VM&#8217;s involved CPU cores, RAM, NIC types, anything else I could think of.</li></ul>



<p>In the end, I couldn&#8217;t do anything to really change the results. &nbsp;They held pretty steady at 3Gbps.</p>



<h4 id="speedtest">speedtest</h4>



<p>As mentioned above, probably a throwaway test. &nbsp;I just happened to run this test when my network was a little bit busier.</p>



<figure class="wp-block-image"><img loading="lazy" width="804" height="170" src="https://blog.kroy.io/wp-content/uploads/2019/08/chr-speedtest.png" alt="" class="wp-image-42" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/chr-speedtest.png 804w, https://blog.kroy.io/wp-content/uploads/2019/08/chr-speedtest-300x63.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/chr-speedtest-768x162.png 768w" sizes="(max-width: 804px) 100vw, 804px" /></figure>



<h4 id="cpuusage">cpu usage</h4>



<p>Interestingly enough, the CPU usage on the CHR is quite a bit higher, despite also Linux. &nbsp;I&#8217;m guessing this is attributed to the fact that quite a few networking enhancements and optimizations have occurred in later Linux kernel versions + FRR.</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="477" src="https://blog.kroy.io/wp-content/uploads/2019/08/chr-cpuusage-speedtest-1024x477.png" alt="" class="wp-image-43" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/chr-cpuusage-speedtest-1024x477.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/chr-cpuusage-speedtest-300x140.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/chr-cpuusage-speedtest-768x358.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/chr-cpuusage-speedtest-850x396.png 850w, https://blog.kroy.io/wp-content/uploads/2019/08/chr-cpuusage-speedtest.png 2000w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>I was <em>REALLY </em>disappointed with the Mikrotik results here. &nbsp;I know RouterOS is more than capable of going faster than those speeds, but I&#8217;m not sure what kind of tweaking it takes to get it. &nbsp;Maybe you need lots of sources and destinations. &nbsp;</p>



<p>I know my RB4011 can do almost full 10Gb (unless you are on IPv6 grumble grumble), CCRs can do way more, so I don&#8217;t know why this thing is so slow. &nbsp;And it&#8217;s been like that every time I&#8217;ve tested it, whether on KVM or ESXi. &nbsp;</p>



<hr class="wp-block-separator"/>



<h2 id="freebsd">FreeBSD</h2>



<p>It definitely wouldn&#8217;t be a complete test without also testing two popular players in the FreeBSD world. &nbsp;OPNSense and pfSense.</p>



<p>For these tests, a number of important configuration options were applied:</p>



<ul><li>All hardware offload stuff disabled in the VMs.</li><li>Three VLAN interfaces, WAN/LAN/LAN2 as mapped out above.</li><li>FRR plugin installed.</li><li>NAT completely disabled.</li><li><code>pfctl -d</code> . &nbsp;While it didn&#8217;t really impact these tests, I wanted to make sure it was a level playing field.</li></ul>



<hr class="wp-block-separator"/>



<h3 id="pfsense">pfSense</h3>



<p>I&#8217;ll be honest. &nbsp;I think these *Sense platforms aren&#8217;t really great routers. &nbsp;Can they route intervlan? &nbsp;Sure, but even with FRR somewhat native now, it&#8217;s just a pain and very clunky.</p>



<p>With pfSense, I never actually did get FRR running. &nbsp;It starts, but it just doesn&#8217;t do anything. &nbsp;Not to mention the GUI for it absolutely sucks and is just a confusing mess. &nbsp;It doesn&#8217;t actually impact these tests, but I annoyingly had to create some static routes on my other routers to get everything working. &nbsp;</p>



<h4 id="boottime">boot time</h4>



<p>Not fast, 37 seconds with a few seconds at the bootloader. I&#8217;m also positive I&#8217;ve seen this take considerably longer when it&#8217;s not a basic config.</p>



<h4 id="iperf3results">iperf3 results</h4>



<p>Again these results made me question my testing methodogy a bit:</p>



<pre class="wp-block-code"><code>[ ID] Interval           Transfer     Bitrate
[  5]   0.00-10.04  sec  1.04 GBytes   891 Mbits/sec                  receiver
[  8]   0.00-10.04  sec  1.97 GBytes  1.68 Gbits/sec                  receiver
[SUM]   0.00-10.04  sec  3.01 GBytes  2.57 Gbits/sec                  receiver  </code></pre>



<p>It&#8217;s worth noting that I&#8217;ve personally seen about 6Gbps on decent hardware, with <code>pf</code> enabled, so I know some of this is due to to the hardware. &nbsp;But I also did try some troubleshooting:</p>



<ul><li>A variety of tweaks on both the host and in the VM with hardware offloading</li><li>Using E1000 NICs. &nbsp;Yeah, that didn&#8217;t turn out too well</li></ul>



<figure class="wp-block-image"><img loading="lazy" width="535" height="101" src="https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-speedtest-e1000.png" alt="" class="wp-image-44" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-speedtest-e1000.png 535w, https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-speedtest-e1000-300x57.png 300w" sizes="(max-width: 535px) 100vw, 535px" /></figure>



<ul><li>Breaking out the VLANs on the host instead of in the VM, and passing in three individual NICs.</li></ul>



<p>Nothing really made too much of a difference.</p>



<h4 id="speedtest">speedtest</h4>



<p>Welcome back to the land of <em>probably-not-very-useful-benchmarks</em>. &nbsp;As before, this easily represents gigabit; my network was just busy.</p>



<figure class="wp-block-image"><img loading="lazy" width="522" height="111" src="https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-speedtest.png" alt="" class="wp-image-45" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-speedtest.png 522w, https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-speedtest-300x64.png 300w" sizes="(max-width: 522px) 100vw, 522px" /></figure>



<h4 id="cpuusageduringrouting">cpu usage during routing</h4>



<p>These CPU results are more within line of the CHR results above. &nbsp;Meaning resource-wise, pfSense takes a bit more to route at high-ish (crappy) speeds. &nbsp;</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="522" src="https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-cpuusage-speedtest-1024x522.png" alt="" class="wp-image-46" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-cpuusage-speedtest-1024x522.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-cpuusage-speedtest-300x153.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-cpuusage-speedtest-768x392.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-cpuusage-speedtest-850x433.png 850w, https://blog.kroy.io/wp-content/uploads/2019/08/pfsense-cpuusage-speedtest.png 1310w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<hr class="wp-block-separator"/>



<h3 id="opnsense">OPNSense</h3>



<p>For the most part, OPNSense and pfSense performed mostly identically, to the point where it&#8217;s almost not worth the posting the results. &nbsp;But I will.</p>



<p>I will point out that I was able to get FRR going in about 20 seconds on OPNSense. &nbsp;Whereas on pfSense after hacking around with it for 20 minutes I still couldn&#8217;t get it running.</p>



<p>I&#8217;ll also say that I like some things about the OPNSense UI and absolutely hate others. &nbsp;There are definitely some things buried in weird and unintuitive places. &nbsp;</p>



<h4 id="boottime">boot time</h4>



<p>At 34 seconds with 2 seconds of bootloader, this is a few seconds quicker than pfSense.</p>



<h4 id="iperf3results">iperf3 results</h4>



<p>Within the same range as pfSense, similarly disappointing:</p>



<pre class="wp-block-code"><code>[ ID] Interval           Transfer     Bitrate
[  5]   0.00-10.03  sec  1.29 GBytes  1.10 Gbits/sec                  receiver
[  8]   0.00-10.03  sec  1.80 GBytes  1.54 Gbits/sec                  receiver
[SUM]   0.00-10.03  sec  3.09 GBytes  2.65 Gbits/sec                  receiver</code></pre>



<h4 id="speedtest">speedtest</h4>



<p>Yet another <em>basically-gigabit</em> screenshot:</p>



<figure class="wp-block-image"><img loading="lazy" width="752" height="150" src="https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-speedtest.png" alt="" class="wp-image-47" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-speedtest.png 752w, https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-speedtest-300x60.png 300w" sizes="(max-width: 752px) 100vw, 752px" /></figure>



<h4 id="cpuduringrouting">cpu during routing</h4>



<p>As with pfSense, the CPU definitely spikes and stays a bit higher during heavy routing. &nbsp;</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="467" src="https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-cpuusage-speedtest-1024x467.png" alt="" class="wp-image-48" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-cpuusage-speedtest-1024x467.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-cpuusage-speedtest-300x137.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-cpuusage-speedtest-768x350.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-cpuusage-speedtest-850x388.png 850w, https://blog.kroy.io/wp-content/uploads/2019/08/opnsense-cpuusage-speedtest.png 2000w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<hr class="wp-block-separator"/>



<p><a name="finalresults_kvm"></a></p>



<h2 id="final-results">Final Results</h2>



<p>After all these tests, it appears I&#8217;ll probably be sticking to VyOS or Debian for my routing needs. &nbsp;Mostly just for pure routing tasks, which is a lot of what I end up labbing up, &nbsp;Linux seems to do it a bit better.</p>



<figure class="wp-block-table"><table class="has-fixed-layout"><tbody><tr><th>Router</th><th>Boot Time<sup>*</sup></th><th>Intervlan iperf3</th><th>WAN Speedtest<sup>**</sup></th></tr><tr><td>VyOS</td><td>37 seconds<sup>***</sup></td><td>12.3 Gbps</td><td>878Mbps down/918Mbps up</td></tr><tr><td>Debian/FRR</td><td>19 seconds</td><td>12.2 Gbps</td><td>957Mbps down/932Mbps up</td></tr><tr><td>CHR</td><td>12 seconds</td><td>3.01 Gbps</td><td>845Mbps down/868Mbps up</td></tr><tr><td>OPNSense</td><td>34 seconds</td><td>2.65 Gbps</td><td>888Mbps down/930Mbps up</td></tr><tr><td>pfSense</td><td>37 seconds</td><td>2.57 Gbps</td><td>874Mbps down/896Mbps up</td></tr></tbody></table></figure>



<ul><li>* boot times all include bootloader waits. &nbsp;Linux-based was usually about 5 seconds (except CHR). &nbsp;FreeBSD-based is 2 seconds.</li><li>** All results are within a margin of error that says &#8220;<em>gigabit-capable</em>&#8220;. &nbsp;My network was somewhat busy at the time I ran the speedtests, not to mention this lab is buried behind two other different routers.</li><li>*** I&#8217;ve seen VyOS take considerably longer once more complex configurations are applied. Upwards of a minute or more. &nbsp;</li></ul>



<p>As mentioned, I&#8217;ve seen pfSense run up to 6-7Gbps. &nbsp;So the slow speeds on pfSense and OPNSense here are almost certainly due to the host. &nbsp;Along the same line, my VyOS routers that run on my E5-2540v4 can route at 30Gbps or faster, so the 12Gbps observed here is slow. &nbsp;</p>



<p>As far as the CHR is concerned, I&#8217;m not sure. &nbsp;I&#8217;ve done extensive testing with them, and even with the unlimited license, I&#8217;ve never see very good performance out of them, at least not without 100 hosts behind them. &nbsp;</p>



<hr class="wp-block-separator"/>



<h2 id="the-esxi-mutation">The ESXi Mutation</h2>



<p>So before I close this up, I decided to spin up one more set of tests on ESXi. &nbsp;The painfully low pfSense and CHR numbers made me really believe that there was an incompatibility somewhere. &nbsp;Maybe &nbsp;CHR and pfSense just really don&#8217;t like the virtio drivers.</p>



<p>I also only tested VyOS, CHR, and pfSense, since the Debian and OPNSense numbers were largely duplicative.</p>



<p><!--kg-card-begin: html--><a name="finalresults_esxi"></a><!--kg-card-end: html--><!--kg-card-begin: html--></p>



<figure class="wp-block-table"><table class=""><tbody><tr><th>Router</th><th>Boot Time</th><th>Intervlan iperf3</th></tr><tr><td>VyOS</td><td>32 seconds</td><td>17.3 Gbps</td></tr><tr><td>CHR</td><td>17 seconds</td><td>7.63 Gbps</td></tr><tr><td>pfSense</td><td>33 seconds</td><td>5.61 Gbps</td></tr></tbody></table></figure>



<p>As far as boot times are concerned, the shorter times are caused by being on faster storage, though I don&#8217;t know why the CHR decided to be an outlier. &nbsp;</p>



<p>For VyOS, the slightly increased number tracks with my expectations due to CPU and memory bandwidth. &nbsp;My ESXi server is an E5-2640v4, which runs circles around a D-1521. &nbsp;</p>



<p>For the CHR and pfSense, I wouldn&#8217;t expect the numbers to be over double just due to the platform change, so I have to believe it&#8217;s mostly due to some driver situation.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">33</post-id>	</item>
		<item>
		<title>Abusing the QNAP TS-831x with ZFS</title>
		<link>https://blog.kroy.io/2017/07/05/abusing-the-qnap-ts-831x-with-zfs/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=abusing-the-qnap-ts-831x-with-zfs</link>
		
		<dc:creator><![CDATA[Kroy]]></dc:creator>
		<pubDate>Thu, 06 Jul 2017 00:01:08 +0000</pubDate>
				<category><![CDATA[Debian]]></category>
		<category><![CDATA[QNAP]]></category>
		<category><![CDATA[ZFS]]></category>
		<guid isPermaLink="false">https://blog2.kroy.io/2017/07/05/abusing-the-qnap-ts-831x-with-zfs/</guid>

					<description><![CDATA[Lately for my business, I&#8217;ve been recommending the QNAP TS-831x to clients. As I have a few of them sitting around my lab now, I decided to abuse them a&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Lately for my business, I&#8217;ve been recommending the QNAP TS-831x to clients. As I have a few of them sitting around my lab now, I decided to abuse them a little.</p>



<hr class="wp-block-separator"/>



<p>In the world of SOHO NAS devices, most people would solidly recommend Synology. Arguably, the software is second to none, but then again so is the price tag. And after a very bad experience with a DS2015xs, I decided to give QNAP a try.</p>



<p>Since then, I&#8217;ve been recommending the TS-831x to clients. For the price, the performance is stellar and it&#8217;s a steal at $799. It has dual-SFP+ ports, software that is practically indistinguishable from Synology, and eight 6Gbps SATA ports, which is something that the equivalent Synology didn&#8217;t have until this year&#8217;s hardware update. It does have a pretty lackluster ARM CPU in it, so I definitely wouldn&#8217;t recommend it for people that like to mix their compute and their storage.</p>



<p>As I have a few of these devices now as spares and backup, I decided it was time to explore the possibilities of them.</p>



<h4 id="virtualjbod">Virtual JBOD</h4>



<p>I&#8217;ve started using ZFS again as my primary storage, and I would love to be able to somehow use one of these TS-831x as part of a ZFS pool for a receive target as a fourth tier backup.</p>



<p>A capability that the TS-831x advertises is &#8220;Virtual JBOD&#8221;. Digging into that concept, the idea is to export iSCSI LUNs from other devices and use them as part of the storage pool on the QNAP.</p>



<p>On the QNAP, with the basic RAID that it uses, that&#8217;s reasonably safe. Of course, with ZFS, that&#8217;s not what I want.</p>



<p>I wanted it the opposite direction.</p>



<hr class="wp-block-separator"/>



<p><strong>The players:</strong></p>



<ul><li>A QNAP TS-831x</li><li>5x6TB Western Digital Red Drives (the 5400 RPM non-pro version)</li><li>Ubuntu 17.04 VM on ESXi</li><li>End-to-end 10Gb</li></ul>



<hr class="wp-block-separator"/>



<h2 id="donoteverdothis">DO NOT EVER DO THIS</h2>



<p>When you are talking about ZFS, there is a hard and fast rule. Give ZFS direct access to the disks. Many of the horror stories you hear about people losing data starts with something like &#8220;I have a RAID card and not an HBA, so I created single RAID stripes out of the disks, etc&#8221;.</p>



<p>Needless to say, doing something like this is probably not recommended:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="550" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_storage-1024x550.png" alt="" class="wp-image-154" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-1024x550.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-300x161.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-768x412.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-1600x859.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="581" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-1024x581.png" alt="" class="wp-image-155" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-1024x581.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-300x170.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-768x436.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-1600x908.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>For the uninitiated, I&#8217;ve taken five 6TB drives in a TS-831x, created separate storage pools out of them, and exported each pool as an iSCSI target.</p>



<h5 id="error">Error</h5>



<p>I&#8217;m not entirely sure this is the best way to set this up, but it was the only way I could make it work. Of course the QNAP is screaming the entire way. It wants to be a complete storage+media device, not just a slave for some drives.</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="399" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-1024x399.png" alt="" class="wp-image-156" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-1024x399.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-300x117.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-768x299.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1.png 1238w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="598" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_no_like-1024x598.png" alt="" class="wp-image-157" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-1024x598.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-300x175.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-768x449.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-1600x935.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<hr class="wp-block-separator"/>



<h4 id="zfsandubuntuandqnap">ZFS and Ubuntu and QNAP</h4>



<p>The goal of all of this was to be able to take periodic ZFS snapshots of a live pool, send them to the QNAP. Of course unless you are using Enterprise-level QNAP devices, ZFS isn&#8217;t supported.</p>



<p>After many years of FreeNAS, I&#8217;ve started using Ubuntu for all my ZFS needs.</p>



<p>iSCSI is simple to set up now and well-covered on one of their <a href="https://help.ubuntu.com/lts/serverguide/iscsi-initiator.html">guides</a>. After the normal ZFS-creation <a href="https://wiki.ubuntu.com/Kernel/Reference/ZFS">stuff</a>, I had a RAIDz1 pool of my QNAP drives.</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="465" src="https://blog2.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-1024x465.png" alt="" class="wp-image-158" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-1024x465.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-300x136.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-768x348.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-1600x726.png 1600w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1.png 1794w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>It&#8217;s important to note that on every reboot, I had to manually import the pool. I&#8217;m sure it&#8217;s just a simple dependency loading-order issue, ZFS is loading before iSCSI. For this testing and backup, I didn&#8217;t bother to fix it.</p>



<h5 id="sendandreceive">Send and Receive</h5>



<p>Once I had a working ZFS pool running on the TS-831x via an Ubuntu VM, it was time to get to work. On the original zpool:</p>



<pre class="wp-block-code"><code>zpool get allocated
NAME  PROPERTY   VALUE  SOURCE
tank  allocated  12.2T  -</code></pre>



<p>12.2T of data should be enough to throughly break it in.</p>



<p>I assumed that if the setup was going to break, a ZFS send/receive would be a good way to cause it to implode.</p>



<p><code>zfs send -R tank@1498833771| ssh root@qnap-zfs zfs recv qnaptank/tankbackup</code></p>



<p>While loading, it showed decent performance:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="449" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-1024x449.png" alt="" class="wp-image-159" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-1024x449.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-300x132.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-768x337.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-1600x702.png 1600w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark.png 1604w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<h5 id="crashandburn">Crash and Burn</h5>



<p>Well it didn&#8217;t actually crash or burn to my surprise.</p>



<p>My custom ZFS snapshot send/receive management script had a bug in it. So I ended up sending the 12.2T of data twice because my script trashed the first copy. That means my stress test was inadvertantly doubled.</p>



<p>Anyway, exactly 24 hours and 13 minutes later (after starting over), I had a copy of 12.2T of data on the ZFS/QNAP setup. That&#8217;s a solid 160MB/s to a RAIDz1 over SSH and iSCSI. There were no drive or other checksum errors, and some random verification of the data showed it was fully intact.</p>



<p>And even subsequent sends/receives of updated snapshots completed without issue, though those are usually slower than the initial:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="127" src="https://blog2.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-1024x127.png" alt="" class="wp-image-160" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-1024x127.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-300x37.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-768x95.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-1600x198.png 1600w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance.png 1696w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="178" src="https://blog2.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-1024x178.png" alt="" class="wp-image-161" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-1024x178.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-300x52.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-768x134.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final.png 1288w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>Migrating a VM to the new &#8220;QNAP ZFS&#8221; array, it showed decent performance when running disk tests inside of the VM:</p>



<figure class="wp-block-image"><img loading="lazy" width="964" height="846" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark.png" alt="" class="wp-image-162" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark.png 964w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark-300x263.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark-768x674.png 768w" sizes="(max-width: 964px) 100vw, 964px" /></figure>



<p>For RAIDz1 on slow drives, over an iSCSI connection, not bad at all.</p>



<h5 id="conclusion">Conclusion</h5>



<p>It goes without saying that this is probably not a setup someone should actually run. At some point I&#8217;m imagining the pool is going to explode. For now, it&#8217;s fine as a 4th level of backup.</p>



<p>If nothing else, it&#8217;s analogous to setting up individual RAID0 on 5 separate drives (which is a huge NO-NO), and then exporting it over a network connection (also probably a huge NO-NO).</p>



<p>I&#8217;m currently gathering and writing up some benchmarks on one of these TS-831x devices, just using them as intended. The result of these will be posted later, but I will say, these are fully capable devices for any basic home or small business setup.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">24</post-id>	</item>
	</channel>
</rss>
