<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>QNAP &#8211; blog.kroy.io</title>
	<atom:link href="https://blog.kroy.io/category/qnap/feed/" rel="self" type="application/rss+xml" />
	<link>https://blog.kroy.io/</link>
	<description>computers, tech, and whatever other random stuff crosses my mind.</description>
	<lastBuildDate>Mon, 07 Dec 2020 15:37:33 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.5.4</generator>

<image>
	<url>https://blog.kroy.io/wp-content/uploads/2020/04/cropped-android-chrome-512x512-3-32x32.png</url>
	<title>QNAP &#8211; blog.kroy.io</title>
	<link>https://blog.kroy.io/</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">166765678</site>	<item>
		<title>Abusing the QNAP TS-831x with ZFS</title>
		<link>https://blog.kroy.io/2017/07/05/abusing-the-qnap-ts-831x-with-zfs/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=abusing-the-qnap-ts-831x-with-zfs</link>
		
		<dc:creator><![CDATA[Kroy]]></dc:creator>
		<pubDate>Thu, 06 Jul 2017 00:01:08 +0000</pubDate>
				<category><![CDATA[Debian]]></category>
		<category><![CDATA[QNAP]]></category>
		<category><![CDATA[ZFS]]></category>
		<guid isPermaLink="false">https://blog2.kroy.io/2017/07/05/abusing-the-qnap-ts-831x-with-zfs/</guid>

					<description><![CDATA[Lately for my business, I&#8217;ve been recommending the QNAP TS-831x to clients. As I have a few of them sitting around my lab now, I decided to abuse them a&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Lately for my business, I&#8217;ve been recommending the QNAP TS-831x to clients. As I have a few of them sitting around my lab now, I decided to abuse them a little.</p>



<hr class="wp-block-separator"/>



<p>In the world of SOHO NAS devices, most people would solidly recommend Synology. Arguably, the software is second to none, but then again so is the price tag. And after a very bad experience with a DS2015xs, I decided to give QNAP a try.</p>



<p>Since then, I&#8217;ve been recommending the TS-831x to clients. For the price, the performance is stellar and it&#8217;s a steal at $799. It has dual-SFP+ ports, software that is practically indistinguishable from Synology, and eight 6Gbps SATA ports, which is something that the equivalent Synology didn&#8217;t have until this year&#8217;s hardware update. It does have a pretty lackluster ARM CPU in it, so I definitely wouldn&#8217;t recommend it for people that like to mix their compute and their storage.</p>



<p>As I have a few of these devices now as spares and backup, I decided it was time to explore the possibilities of them.</p>



<h4 id="virtualjbod">Virtual JBOD</h4>



<p>I&#8217;ve started using ZFS again as my primary storage, and I would love to be able to somehow use one of these TS-831x as part of a ZFS pool for a receive target as a fourth tier backup.</p>



<p>A capability that the TS-831x advertises is &#8220;Virtual JBOD&#8221;. Digging into that concept, the idea is to export iSCSI LUNs from other devices and use them as part of the storage pool on the QNAP.</p>



<p>On the QNAP, with the basic RAID that it uses, that&#8217;s reasonably safe. Of course, with ZFS, that&#8217;s not what I want.</p>



<p>I wanted it the opposite direction.</p>



<hr class="wp-block-separator"/>



<p><strong>The players:</strong></p>



<ul><li>A QNAP TS-831x</li><li>5x6TB Western Digital Red Drives (the 5400 RPM non-pro version)</li><li>Ubuntu 17.04 VM on ESXi</li><li>End-to-end 10Gb</li></ul>



<hr class="wp-block-separator"/>



<h2 id="donoteverdothis">DO NOT EVER DO THIS</h2>



<p>When you are talking about ZFS, there is a hard and fast rule. Give ZFS direct access to the disks. Many of the horror stories you hear about people losing data starts with something like &#8220;I have a RAID card and not an HBA, so I created single RAID stripes out of the disks, etc&#8221;.</p>



<p>Needless to say, doing something like this is probably not recommended:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="550" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_storage-1024x550.png" alt="" class="wp-image-154" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-1024x550.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-300x161.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-768x412.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_storage-1600x859.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="581" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-1024x581.png" alt="" class="wp-image-155" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-1024x581.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-300x170.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-768x436.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_iscsi-1600x908.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>For the uninitiated, I&#8217;ve taken five 6TB drives in a TS-831x, created separate storage pools out of them, and exported each pool as an iSCSI target.</p>



<h5 id="error">Error</h5>



<p>I&#8217;m not entirely sure this is the best way to set this up, but it was the only way I could make it work. Of course the QNAP is screaming the entire way. It wants to be a complete storage+media device, not just a slave for some drives.</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="399" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-1024x399.png" alt="" class="wp-image-156" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-1024x399.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-300x117.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1-768x299.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_warnings-1.png 1238w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="598" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_no_like-1024x598.png" alt="" class="wp-image-157" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-1024x598.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-300x175.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-768x449.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_no_like-1600x935.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<hr class="wp-block-separator"/>



<h4 id="zfsandubuntuandqnap">ZFS and Ubuntu and QNAP</h4>



<p>The goal of all of this was to be able to take periodic ZFS snapshots of a live pool, send them to the QNAP. Of course unless you are using Enterprise-level QNAP devices, ZFS isn&#8217;t supported.</p>



<p>After many years of FreeNAS, I&#8217;ve started using Ubuntu for all my ZFS needs.</p>



<p>iSCSI is simple to set up now and well-covered on one of their <a href="https://help.ubuntu.com/lts/serverguide/iscsi-initiator.html">guides</a>. After the normal ZFS-creation <a href="https://wiki.ubuntu.com/Kernel/Reference/ZFS">stuff</a>, I had a RAIDz1 pool of my QNAP drives.</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="465" src="https://blog2.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-1024x465.png" alt="" class="wp-image-158" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-1024x465.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-300x136.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-768x348.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1-1600x726.png 1600w, https://blog.kroy.io/wp-content/uploads/2019/08/zpoolimport-1.png 1794w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>It&#8217;s important to note that on every reboot, I had to manually import the pool. I&#8217;m sure it&#8217;s just a simple dependency loading-order issue, ZFS is loading before iSCSI. For this testing and backup, I didn&#8217;t bother to fix it.</p>



<h5 id="sendandreceive">Send and Receive</h5>



<p>Once I had a working ZFS pool running on the TS-831x via an Ubuntu VM, it was time to get to work. On the original zpool:</p>



<pre class="wp-block-code"><code>zpool get allocated
NAME  PROPERTY   VALUE  SOURCE
tank  allocated  12.2T  -</code></pre>



<p>12.2T of data should be enough to throughly break it in.</p>



<p>I assumed that if the setup was going to break, a ZFS send/receive would be a good way to cause it to implode.</p>



<p><code>zfs send -R tank@1498833771| ssh root@qnap-zfs zfs recv qnaptank/tankbackup</code></p>



<p>While loading, it showed decent performance:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="449" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-1024x449.png" alt="" class="wp-image-159" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-1024x449.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-300x132.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-768x337.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark-1600x702.png 1600w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_load_benchmark.png 1604w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<h5 id="crashandburn">Crash and Burn</h5>



<p>Well it didn&#8217;t actually crash or burn to my surprise.</p>



<p>My custom ZFS snapshot send/receive management script had a bug in it. So I ended up sending the 12.2T of data twice because my script trashed the first copy. That means my stress test was inadvertantly doubled.</p>



<p>Anyway, exactly 24 hours and 13 minutes later (after starting over), I had a copy of 12.2T of data on the ZFS/QNAP setup. That&#8217;s a solid 160MB/s to a RAIDz1 over SSH and iSCSI. There were no drive or other checksum errors, and some random verification of the data showed it was fully intact.</p>



<p>And even subsequent sends/receives of updated snapshots completed without issue, though those are usually slower than the initial:</p>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="127" src="https://blog2.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-1024x127.png" alt="" class="wp-image-160" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-1024x127.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-300x37.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-768x95.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance-1600x198.png 1600w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance.png 1696w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<figure class="wp-block-image"><img loading="lazy" width="1024" height="178" src="https://blog2.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-1024x178.png" alt="" class="wp-image-161" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-1024x178.png 1024w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-300x52.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final-768x134.png 768w, https://blog.kroy.io/wp-content/uploads/2019/08/zfs_send_to_qnap_performance_final.png 1288w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>Migrating a VM to the new &#8220;QNAP ZFS&#8221; array, it showed decent performance when running disk tests inside of the VM:</p>



<figure class="wp-block-image"><img loading="lazy" width="964" height="846" src="https://blog2.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark.png" alt="" class="wp-image-162" srcset="https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark.png 964w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark-300x263.png 300w, https://blog.kroy.io/wp-content/uploads/2019/08/qnap_zfs_diskmark-768x674.png 768w" sizes="(max-width: 964px) 100vw, 964px" /></figure>



<p>For RAIDz1 on slow drives, over an iSCSI connection, not bad at all.</p>



<h5 id="conclusion">Conclusion</h5>



<p>It goes without saying that this is probably not a setup someone should actually run. At some point I&#8217;m imagining the pool is going to explode. For now, it&#8217;s fine as a 4th level of backup.</p>



<p>If nothing else, it&#8217;s analogous to setting up individual RAID0 on 5 separate drives (which is a huge NO-NO), and then exporting it over a network connection (also probably a huge NO-NO).</p>



<p>I&#8217;m currently gathering and writing up some benchmarks on one of these TS-831x devices, just using them as intended. The result of these will be posted later, but I will say, these are fully capable devices for any basic home or small business setup.</p>
]]></content:encoded>
					
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">24</post-id>	</item>
	</channel>
</rss>
